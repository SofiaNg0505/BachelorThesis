{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      [(None, 32, 32, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_layer_1 (Conv2D)   (None, 32, 32, 32)   320         encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "encoder_relu_1 (ReLU)           (None, 32, 32, 32)   0           encoder_conv_layer_1[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bn_1 (BatchNormalizatio (None, 32, 32, 32)   128         encoder_relu_1[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_layer_2 (Conv2D)   (None, 16, 16, 64)   18496       encoder_bn_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_relu_2 (ReLU)           (None, 16, 16, 64)   0           encoder_conv_layer_2[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bn_2 (BatchNormalizatio (None, 16, 16, 64)   256         encoder_relu_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_layer_3 (Conv2D)   (None, 8, 8, 64)     36928       encoder_bn_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_relu_3 (ReLU)           (None, 8, 8, 64)     0           encoder_conv_layer_3[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bn_3 (BatchNormalizatio (None, 8, 8, 64)     256         encoder_relu_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "encoder_conv_layer_4 (Conv2D)   (None, 8, 8, 64)     36928       encoder_bn_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "encoder_relu_4 (ReLU)           (None, 8, 8, 64)     0           encoder_conv_layer_4[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "encoder_bn_4 (BatchNormalizatio (None, 8, 8, 64)     256         encoder_relu_4[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 4096)         0           encoder_bn_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "mu (Dense)                      (None, 2)            8194        flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_variance (Dense)            (None, 2)            8194        flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "encoder_output (Lambda)         (None, 2)            0           mu[0][0]                         \n",
      "                                                                 log_variance[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 109,956\n",
      "Trainable params: 109,508\n",
      "Non-trainable params: 448\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"decoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "decoder_input (InputLayer)   [(None, 2)]               0         \n",
      "_________________________________________________________________\n",
      "decoder_dense (Dense)        (None, 4096)              12288     \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 8, 8, 64)          36928     \n",
      "_________________________________________________________________\n",
      "decoder_relu_1 (ReLU)        (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_1 (BatchNormaliza (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "decoder_relu_2 (ReLU)        (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_2 (BatchNormaliza (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "decoder_relu_3 (ReLU)        (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "decoder_bn_3 (BatchNormaliza (None, 32, 32, 64)        256       \n",
      "_________________________________________________________________\n",
      "decoder_conv_transpose_layer (None, 32, 32, 1)         577       \n",
      "_________________________________________________________________\n",
      "linear_layer (Activation)    (None, 32, 32, 1)         0         \n",
      "=================================================================\n",
      "Total params: 124,417\n",
      "Trainable params: 124,033\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "Model: \"autoencoder\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder_input (InputLayer)   [(None, 32, 32, 1)]       0         \n",
      "_________________________________________________________________\n",
      "encoder (Model)              (None, 2)                 109956    \n",
      "_________________________________________________________________\n",
      "decoder (Model)              (None, 32, 32, 1)         124417    \n",
      "=================================================================\n",
      "Total params: 234,373\n",
      "Trainable params: 233,541\n",
      "Non-trainable params: 832\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "from tensorflow.keras.losses import MSE\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, ReLU, BatchNormalization,Flatten, Dense, Reshape, Conv2DTranspose, Activation, Lambda\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"for 3D we will use Conv3D\"\"\"\n",
    "\n",
    "#https://www.youtube.com/watch?v=A6mdOEPGM1E\n",
    "\n",
    "#GOAL:\n",
    "#Extract 2D slices and use the VAE\n",
    "#Then tur the VAE into a 3d VAE and use the entire 3D information\n",
    "\n",
    "data = np.load('3D_dataset.npy')\n",
    "#The data contains the density field obtained by applying the Zel'dovich\n",
    "#approximation on a 3D grid of particles and then interpolating the \n",
    "#particle distribution to a density field. \n",
    "#There are 32x32x32. Array shape is 8000,32,32,32. \n",
    " \n",
    "\"\"\"Autoencoder-the plot isn't symmetricalaround origin, how do we then\n",
    "samplea point for generation? \n",
    "Some labels are represented over small areas, other over large ones,\n",
    "so we have a lack of diversity. There are also gaps between coloured points,\n",
    "so some generated images will be poor. \n",
    "Thats why we use VAE.\n",
    "\"\"\"\n",
    "\n",
    "#data disabling eager execution. The implementation that we will be given for this VAE woesnt\n",
    "#work foreager execution- its a programming enviroment that tensorflow has that calculate and evaluate operation is possible\n",
    "#before the graph is really built\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "\n",
    "class VAE:\n",
    "    \"\"\"\n",
    "    VAE represents a Deep Convolutional variational autoencoder architecture\n",
    "    with mirrored encoder and decoder components.\n",
    "    \n",
    "    When training the model, we need to be able to calculate the relationship of each parameter in the network\n",
    "    with respect to the final output loss using a technique known as backpropagation. But in this case\n",
    "    use the clever trick ''reparameterization trick'' \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 input_shape,\n",
    " \n",
    "                 conv_filters,#tuble/lists, each item represent number of filters for each layer\n",
    "                 conv_kernels,\n",
    "                 conv_strides, #strides\n",
    "                 latent_space_dim):\n",
    "        self.input_shape = input_shape # [28, 28, 1] #assign all of these argument to instant attributes\n",
    "        self.conv_filters = conv_filters # [2, 4, 8]\n",
    "        self.conv_kernels = conv_kernels # [3, 5, 3]\n",
    "        self.conv_strides = conv_strides # [1, 2, 2]\n",
    "        self.latent_space_dim = latent_space_dim # 2\n",
    "        self.reconstruction_loss_weight = 1000\n",
    "\n",
    "        self.encoder = None\n",
    "        self.decoder = None\n",
    "        self.model = None\n",
    "\n",
    "        self._num_conv_layers = len(conv_filters)\n",
    "        self._shape_before_bottleneck = None\n",
    "        self._model_input = None\n",
    "\n",
    "        self._build()\n",
    "\n",
    "    def summary(self):\n",
    "        self.encoder.summary()\n",
    "        self.decoder.summary()\n",
    "        self.model.summary()\n",
    "#####################################################################################################\n",
    "    def compile(self, learning_rate=0.0001):\n",
    "        optimizer = Adam(learning_rate=learning_rate)\n",
    "        self.model.compile(optimizer=optimizer,\n",
    "                           loss=self._calculate_combined_loss,\n",
    "                           metrics=[self._calculate_reconstruction_loss,\n",
    "                                    self._calculate_kl_loss]) #metrics are for so we can see the \n",
    "                        # losses  in the meantime as we are training\n",
    "                            \n",
    "    def train(self, x_train, batch_size, num_epochs):\n",
    "        history=self.model.fit(x_train,\n",
    "                       x_train,validation_split=0.3,\n",
    "                       batch_size=batch_size,\n",
    "                       epochs=num_epochs,\n",
    "                       shuffle=True)\n",
    "        golden_size = lambda width: (width, 2. * width / (1 + np.sqrt(5)))\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=golden_size(7))\n",
    "        \n",
    "        hist_dff = np.log((pd.DataFrame(history.history)))\n",
    "        hist_df=hist_dff.loc[:,['loss','val_loss']]\n",
    "\n",
    "        hist_df.plot(hist_df)\n",
    "        \n",
    "        print(hist_dff,hist_df)\n",
    "        \n",
    "        ax.set_ylabel('NELBO')\n",
    "        ax.set_xlabel('Number of epochs')\n",
    "        \n",
    "        ax.set_ylim(((.99*hist_df[1:].values.min())), \n",
    "                    (1.1*hist_df[1:].values.max()))\n",
    "        plt.show()\n",
    "        \n",
    "####################################################################################################\n",
    "    def save(self, save_folder=\".\"):\n",
    "        self._create_folder_if_it_doesnt_exist(save_folder)\n",
    "        self._save_parameters(save_folder)\n",
    "        self._save_weights(save_folder)\n",
    "\n",
    "    def load_weights(self, weights_path):\n",
    "        self.model.load_weights(weights_path)\n",
    "\n",
    "    def reconstruct(self, images):\n",
    "        latent_representations = self.encoder.predict(images)\n",
    "        reconstructed_images = self.decoder.predict(latent_representations)\n",
    "        return reconstructed_images, latent_representations\n",
    "\n",
    "    @classmethod\n",
    "    def load(cls, save_folder=\".\"):\n",
    "        parameters_path = os.path.join(save_folder, \"parameters.pkl\")\n",
    "        with open(parameters_path, \"rb\") as f:\n",
    "            parameters = pickle.load(f)\n",
    "        autoencoder = VAE(*parameters) #*parameters stands for the lists of parameters as positional arguments\n",
    "        weights_path = os.path.join(save_folder, \"weights.h5\")\n",
    "        autoencoder.load_weights(weights_path)\n",
    "        return autoencoder\n",
    "\n",
    "    def _calculate_combined_loss(self, y_target, y_predicted): #custom implementation of the loss function. \n",
    "        reconstruction_loss = self._calculate_reconstruction_loss(y_target, y_predicted)\n",
    "        kl_loss = self._calculate_kl_loss(y_target, y_predicted)\n",
    "        combined_loss = self.reconstruction_loss_weight * reconstruction_loss\\\n",
    "                                                         + kl_loss\n",
    "        return combined_loss\n",
    "\n",
    "    def _calculate_reconstruction_loss(self, y_target, y_predicted):\n",
    "        error = y_target - y_predicted\n",
    "        reconstruction_loss = tf.reduce_mean(tf.reduce_sum((K.mean(K.square(error), axis=[1, 2,3]))))\n",
    "        return reconstruction_loss\n",
    "\n",
    "    def _calculate_kl_loss(self, y_target, y_predicted):#In this case we want the difference between\n",
    "        #our Gaussian distribution from the standaard multivariate normal distribution. We use this 'distance' as a loss\n",
    "        #because we want to pull our Gaussian ditr towards the standard Gaussian Distr. \n",
    "        kl_loss = tf.reduce_mean((-0.5*K.sum(1 + self.log_variance - tf.square(self.mu) -tf.exp(self.log_variance), axis=1))) #which axis we want to sum \n",
    "        return kl_loss \n",
    "\n",
    "    def _create_folder_if_it_doesnt_exist(self, folder):\n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "\n",
    "    def _save_parameters(self, save_folder):\n",
    "        parameters = [\n",
    "            self.input_shape,\n",
    "            self.conv_filters,\n",
    "            self.conv_kernels,\n",
    "            self.conv_strides,\n",
    "            self.latent_space_dim\n",
    "        ]\n",
    "        save_path = os.path.join(save_folder, \"parameters.pkl\")\n",
    "        with open(save_path, \"wb\") as f: #writing mode, binary file and f is file\n",
    "            pickle.dump(parameters, f)\n",
    "\n",
    "    def _save_weights(self, save_folder):\n",
    "        save_path = os.path.join(save_folder, \"weights.h5\") #h5 is a frmat that comes with keras.\n",
    "        #Used for storing weights using the keras API.\n",
    "        self.model.save_weights(save_path)\n",
    " \n",
    "    def _build(self): #architecture of the model\n",
    "        self._build_encoder()\n",
    "        self._build_decoder()\n",
    "        self._build_autoencoder()\n",
    "\n",
    "    def _build_autoencoder(self):\n",
    "        model_input = self._model_input\n",
    "        model_output = self.decoder(self.encoder(model_input))\n",
    "        self.model = Model(model_input, model_output, name=\"autoencoder\")\n",
    "############################################################################################################################3\n",
    "    def _build_decoder(self):\n",
    "        decoder_input = self._add_decoder_input()\n",
    "        dense_layer = self._add_dense_layer(decoder_input)\n",
    "        reshape_layer = self._add_reshape_layer(dense_layer)\n",
    "        conv_transpose_layers = self._add_conv_transpose_layers(reshape_layer)\n",
    "        decoder_output = self._add_decoder_output(conv_transpose_layers)\n",
    "        self.decoder = Model(decoder_input, decoder_output, name=\"decoder\")\n",
    "\n",
    "    def _add_decoder_input(self):\n",
    "        return Input(shape=self.latent_space_dim, name=\"decoder_input\")\n",
    "\n",
    "    def _add_dense_layer(self, decoder_input):\n",
    "        num_neurons = np.prod(self._shape_before_bottleneck) # [1, 2, 4] -> 8\n",
    "        dense_layer = Dense(num_neurons, name=\"decoder_dense\")(decoder_input)\n",
    "        return dense_layer\n",
    "\n",
    "    def _add_reshape_layer(self, dense_layer):\n",
    "        return Reshape(self._shape_before_bottleneck)(dense_layer)\n",
    "\n",
    "    def _add_conv_transpose_layers(self, x):\n",
    "        \"\"\"Add conv transpose blocks.\"\"\"\n",
    "        # loop through all the conv layers in reverse order and stop at the\n",
    "        # first layer\n",
    "        for layer_index in reversed(range(1, self._num_conv_layers)):\n",
    "            x = self._add_conv_transpose_layer(layer_index, x)\n",
    "        return x\n",
    "\n",
    "    def _add_conv_transpose_layer(self, layer_index, x):\n",
    "        layer_num = self._num_conv_layers - layer_index\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters=self.conv_filters[layer_index],\n",
    "            kernel_size=self.conv_kernels[layer_index],\n",
    "            strides=self.conv_strides[layer_index],\n",
    "            padding=\"same\",\n",
    "            name=f\"decoder_conv_transpose_layer_{layer_num}\"\n",
    "        )\n",
    "        x = conv_transpose_layer(x)\n",
    "        x = ReLU(name=f\"decoder_relu_{layer_num}\")(x)\n",
    "        x = BatchNormalization(name=f\"decoder_bn_{layer_num}\")(x)\n",
    "        return x\n",
    "#\n",
    "    def _add_decoder_output(self, x):\n",
    "        conv_transpose_layer = Conv2DTranspose(\n",
    "            filters=1, #channel 1 because we are working with greyscale\n",
    "            kernel_size=self.conv_kernels[0], #\n",
    "            strides=self.conv_strides[0], #all the data that we pass for 1:st conv layer in terms of kernels and strides. \n",
    "            padding=\"same\",#calculates and adds the padding required to the input image to ensure that the putput has the same shape as the input\n",
    "            name=f\"decoder_conv_transpose_layer_{self._num_conv_layers}\"\n",
    "        )\n",
    "        x = conv_transpose_layer(x)\n",
    "        output_layer = Activation(\"sigmoid\", name=\"linear_layer\")(x)\n",
    "\n",
    "        return output_layer\n",
    "###################################################################################################################################\n",
    "    def _build_encoder(self):\n",
    "        encoder_input = self._add_encoder_input()\n",
    "        conv_layers = self._add_conv_layers(encoder_input)\n",
    "        bottleneck = self._add_bottleneck(conv_layers)\n",
    "        self._model_input = encoder_input\n",
    "        self.encoder = Model(encoder_input, bottleneck, name=\"encoder\")\n",
    "\n",
    "    def _add_encoder_input(self):\n",
    "        return Input(shape=self.input_shape, name=\"encoder_input\")\n",
    "\n",
    "    def _add_conv_layers(self, encoder_input):\n",
    "        \"go through all layers and add to the graph of layers each conv layer\"\n",
    "        \"\"\"Create all convolutional blocks in encoder.\"\"\"\n",
    "        x = encoder_input\n",
    "        for layer_index in range(self._num_conv_layers):\n",
    "            x = self._add_conv_layer(layer_index, x)\n",
    "        return x\n",
    "\n",
    "    def _add_conv_layer(self, layer_index, x):\n",
    "        \"\"\"Add a convolutional block to a graph of layers, consisting of\n",
    "        conv 2d + ReLU + batch normalization.\n",
    "        \"\"\"\n",
    "        layer_number = layer_index + 1\n",
    "        conv_layer = Conv2D(\n",
    "            filters=self.conv_filters[layer_index],\n",
    "            kernel_size=self.conv_kernels[layer_index],\n",
    "            strides=self.conv_strides[layer_index],\n",
    "            padding=\"same\",\n",
    "            name=f\"encoder_conv_layer_{layer_number}\"\n",
    "        )\n",
    "        x = conv_layer(x)\n",
    "        x = ReLU(name=f\"encoder_relu_{layer_number}\")(x)\n",
    "        x = BatchNormalization(name=f\"encoder_bn_{layer_number}\")(x)\n",
    "        return x\n",
    "\n",
    "    def _add_bottleneck(self, x): #VANILLA AUTOENCODER\n",
    "        \"\"\"Flatten data and add bottleneck with Guassian sampling (Dense\n",
    "        layer).\n",
    "        \"\"\"\n",
    "        self._shape_before_bottleneck = K.int_shape(x)[1:]\n",
    "        x = Flatten()(x)\n",
    "        self.mu = Dense(self.latent_space_dim, name=\"mu\")(x) #attribute calles self.mu, apply this new dense layer to the graph.\n",
    "        self.log_variance = Dense(self.latent_space_dim,\n",
    "                                  name=\"log_variance\")(x)\n",
    "\n",
    "        def sample_point_from_normal_distribution(args): #data sampling a datapoint from our gaussian dist that is parametrised through log variance \n",
    "            #and mu. Wrap that funciton within our graph. Keras have a ''lamda layer'' for that.\n",
    "            mu, log_variance = args #We know that we are passing mu and log through lamda layer.\n",
    "            epsilon = K.random_normal(shape=K.shape(self.mu), mean=0.,\n",
    "                                      stddev=1.)  #Epsilon if a sampled point from a standard normal dist. Applying mu and zigma\n",
    "            # will give us a point that is sampled from our gaussian distribution defined by mu and log_var. \n",
    "             \n",
    "            sampled_point = mu + K.exp(log_variance / 2) * epsilon\n",
    "            return sampled_point \n",
    "\n",
    "        x = Lambda(sample_point_from_normal_distribution,\n",
    "                   name=\"encoder_output\")([self.mu, self.log_variance])\n",
    "        return x\n",
    "###############################################################################################################################################################\n",
    "\"\"\"\n",
    "The statements executed by the top-level invocation (anropande)  of the inerpreter, either read from \n",
    "a script file or interactively, are considered part of a model called main\n",
    "\"\"\"\n",
    "if __name__ == \"__main__\":\n",
    "    vae = VAE(\n",
    "        input_shape=(32,32,1), \n",
    "        conv_filters=(32, 64,64,64), #filters are in same dim as input with same nr. of channels, but fewer rows and columns\n",
    "        conv_kernels=(3,3,3,3),\n",
    "        conv_strides=(1,2,2,1), #The amount of movement between applications of the filter to the input image.Default in 2D is (1,1) for the height and the width movement. \n",
    "        latent_space_dim=2\n",
    "    )\n",
    "    vae.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
